- Class: meta
  Course: Y2 Psychology RMS1
  Lesson: Lesson 6 Sampling
  Author: Milan Valasek, Nick Carchedi
  Type: Standard
  Organization: The University of Edinburgh, JHU Biostat
  Version: 0.9

- Class: text
  Output: Good to see you again! In this lesson we will look at sampling from various
    distributions.
  
- Class: text
  Output: One of the great advantages of using a statistical programming language like R is
    its vast collection of tools for simulating random numbers. You have previously used
    the rbinom() function to generate the outcomes of a binomial type experiment such as
    tossing a coin or throwing dice. Today, we'll look at some other handy functions.

- Class: cmd_question
  Output: The first function we'll use to generate random numbers is sample(). Use ?sample
    to pull up the documentation.
  CorrectAnswer: ?sample
  AnswerTests: omnitest(correctExpr='?sample')
  Hint: Use '?sample' to pull up the documentation for the sample() function.

- Class: cmd_question
  Output: "Since the elements you sample are selected at random, you can use the sample()
    function to simulate binomial outcomes (like you did with the rbinom() function). Let's
    simulate rolling four six-sided dice. That basically means that you want to sample, with
    replacement four numbers between 1 and 6. Give it a try now."
  CorrectAnswer: sample(1:6, 4, replace = TRUE)
  AnswerTests: any_of_exprs('sample(1:6, 4, replace = TRUE)', 'sample(1:6, 4, replace = T)')
  Hint: Type sample(1:6, 4, replace = TRUE) to simulate rolling four six-sided dice.

- Class: cmd_question
  Output: Now repeat the command to see how your result differs. (The probability of rolling
    the exact same result is (1/6)^4 = 0.00077, which is pretty small!)
  CorrectAnswer: sample(1:6, 4, replace = TRUE)
  AnswerTests: any_of_exprs('sample(1:6, 4, replace = TRUE)', 'sample(1:6, 4, replace = T)')
  Hint: Type sample(1:6, 4, replace = TRUE) to simulate rolling four six-sided dice again.

- Class: text
  Output: "The \"replace = TRUE\" argument instructs R to randomly select the numbers WITH
    replacement. Sampling with replacement simply means that each number is \"replaced\"
    after it is selected, so that the same number can show up more than once. This is what
    we want here, since what you roll on one die shouldn't affect what you roll on any of
    the others."

- Class: text
  Output: "Just so you know, R defines T and F as TRUE and FALSE, so you could also type \"replace = T\". Swirls are a bit restrictive inasmuch as sometimes it requires you to exactly match the answer I have here, even if there are several possible answers. If TRUE or FALSE doesn't work for an answer, I might have used T or F instead! Sorry!"

- Class: cmd_question
  Output: Now sample 10 numbers between 1 and 20, WITHOUT replacement. To sample without
    replacement, simply leave off the 'replace' argument.
  CorrectAnswer: sample(1:20, 10)
  AnswerTests: match_call('sample(1:20, 10)')
  Hint: Type sample(1:20, 10) to sample 10 numbers between 1 and 20, without replacement.

- Class: text
  Output: Since the last command sampled without replacement, no number appears more than once
    in the output.

- Class: cmd_question
  Output: "LETTERS is a predefined variable in R containing a vector of all 26 upper case
    letters of the English alphabet. Take a look at it now."
  CorrectAnswer: LETTERS
  AnswerTests: omnitest(correctExpr='LETTERS')
  Hint: Type \"LETTERS\" to print its contents to the console.

- Class: cmd_question
  Output: The sample() function can also be used to permute, or rearrange, the elements of a
    vector. Use it to permute the 26 letters of the English alphabet.
  CorrectAnswer: sample(LETTERS)
  AnswerTests: omnitest(correctExpr='sample(LETTERS)')
  Hint: Use sample(LETTERS) to permute all 26 letters of the English alphabet.

- Class: text
  Output: This is identical to taking a sample of size 26 from LETTERS, without replacement.
    When the 'size' argument to sample() is not specified, R takes a sample equal in size to
    the vector from which you are sampling.

- Class: text
  Output: "Now, let's try flipping a coin again. Suppose we want to simulate 100 flips of an
    unfair two-sided coin. This particular coin has a 0.3 probability of landing \"tails\"
    and a 0.7 probability of landing \"heads\"."

- Class: cmd_question
  Output: Let the value 0 represent tails and the value 1 represent heads. Use sample() to
    draw a sample of size 100 from the vector c(0,1), with replacement. Since the coin is
    unfair, we must attach specific probabilities to the values 0 (tails) and 1 (heads) with
    a fourth argument, prob = c(0.3, 0.7). Assign the result to a new variable called flips.
  CorrectAnswer: flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
  AnswerTests: any_of_exprs('flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))', 'flips <- sample(c(0,1), 100, replace = T, prob = c(0.3, 0.7))')
  Hint: 'The following command will produce 100 flips of an unfair coin and assign the result:
    flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))'

- Class: cmd_question
  Output: View the contents of the flips variable.
  CorrectAnswer: flips
  AnswerTests: omnitest(correctExpr='flips')
  Hint: Just type flips to view its contents.

- Class: cmd_question
  Output: Since we set the probability of landing heads on any given flip to be 0.7, we'd
    expect approximately 70 of our coin flips to have the value 1. Count the actual number of
    1s contained in flips using the sum() function.
  CorrectAnswer: sum(flips)
  AnswerTests: omnitest(correctExpr='sum(flips)')
  Hint: sum(flips) will add up all the 1s and 0s, giving you the total number of 1s in flips.

- Class: cmd_question
  Output: A coin flip is a binary outcome (0 or 1) and we are performing 100 independent
    trials (coin flips), so we can use use rbinom() to simulate a binomial random variable.
    Pull up the documentation for rbinom() using ?rbinom.
  CorrectAnswer: ?rbinom
  AnswerTests: omnitest(correctExpr='?rbinom')
  Hint: Type ?rbinom to pull up the help file for rbinom().

- Class: text
  Output: Each probability distribution in R has an r*** function (for "random"), a d***
    function (for "density"), a p*** (for "probability"), and q*** (for "quantile"). Let's
    first explore the r*** functions and then I'll explain the others.

- Class: text
  Output: For a quick refresher, let's start with rbinom() and flipping a coin.
  
- Class: cmd_question
  Output: A binomial random variable represents the number of 'successes' (heads) in a given
    number of independent 'trials' (coin flips). Therefore, we can generate a single random
    variable that represents the number of heads in 100 flips of our unfair coin using
    rbinom(1, size = 100, prob = 0.7). Note that you only specify the probability of 'success'
    (heads) and NOT the probability of 'failure' (tails). Try it now.
  CorrectAnswer: rbinom(1, size = 100, prob = 0.7)
  AnswerTests: match_call('rbinom(1, size = 100, prob = 0.7)')
  Hint: Call rbinom() with n = 1, size = 100, and prob = 0.7.

- Class: cmd_question
  Output: Equivalently, if we want to see all of the 0s and 1s, we can request 100
    observations, each of size 1, with success probability of 0.7. Give it a try, assigning
    the result to a new variable called flips2.
  CorrectAnswer: flips2 <- rbinom(100, size = 1, prob = 0.7)
  AnswerTests: match_call('flips2 <- rbinom(100, size = 1, prob = 0.7)')
  Hint: Call rbinom() with n = 100, size = 1, and prob = 0.7 and assign the result to flips2.

- Class: cmd_question
  Output: View the contents of flips2.
  CorrectAnswer: flips2
  AnswerTests: omnitest('flips2')
  Hint: Type flips2 to view its contents.

- Class: cmd_question
  Output: Now use sum() to count the number of 1s (heads) in flips2. It should be close to 70!
  CorrectAnswer: sum(flips2)
  AnswerTests: omnitest('sum(flips2)')
  Hint: Use sum(flips2) to count the number of 1s.

- Class: cmd_question
  Output: Similar to rbinom(), we can use R to simulate random numbers from many other
    probability distributions. Pull up the documentation for rnorm() now.
  CorrectAnswer: ?rnorm
  AnswerTests: omnitest('?rnorm')
  Hint: Type ?rnorm to view its help file.

- Class: cmd_question
  Output: The standard normal distribution has mean 0 and standard deviation 1. As you can see
    under the 'Usage' section in the documentation, the default values for the 'mean' and 'sd'
    arguments to rnorm() are 0 and 1, respectively. Thus, rnorm(10) will generate 10 random
    numbers from a standard normal distribution. Give it a try.
  CorrectAnswer: rnorm(10)
  AnswerTests: omnitest('rnorm(10)')
  Hint: Use rnorm(10) to generate 10 random numbers from a standard normal distribution.

- Class: cmd_question
  Output: Now do the same, except with a mean of 100 and a standard deviation of 25.
  CorrectAnswer: rnorm(10, 100, 25)
  AnswerTests: match_call('rnorm(10, 100, 25)')
  Hint: Use rnorm(10, mean = 100, sd = 25) to generate 10 random numbers from a normal
    distribution with mean 100 and standard deviation 25.

- Class: text
  Output: Finally, what if we want to simulate 100 *groups* of random numbers, each containing
    5 values generated from a Poisson distribution with mean 10? Let's start with one group of
    5 numbers, then I'll show you how to repeat the operation 100 times in a convenient and
    compact way.
    
- Class: text
  Output: Oh, by the way, the Poisson distribution is useful for modeling the number of
    occurrences of an event in a given time period. For instance, it applies to the number
    of goals in sports involving two competing teams, the number of soldiers killed by
    horse-kicks each year in each corps in the Prussian cavalry, or the number of yeast cells
    used when brewing Guinness. The last example was made famous by one William Sealy Gosset,
    a chemist and statistician working for the brewery. This is not the last time you will
    have heard of him...

- Class: cmd_question
  Output: Anyway, back to R. Generate 5 random values from a Poisson distribution with mean 10.
    Check out the documentation for rpois() if you need help.
  CorrectAnswer: rpois(5, 10)
  AnswerTests: match_call('rpois(5, 10)')
  Hint: Use rpois(5, 10) to generate 5 random numbers from a Poisson distribution with mean 10.

- Class: cmd_question
  Output: Now, you can have R repeat a command using the replicate() function. How about you
    pull up the documentation for replicate()?
  CorrectAnswer: ?replicate
  AnswerTests: omnitest('?replicate')
  Hint: Type ?replicate to view its help file.
  
- Class: cmd_question
  Output: OK, now use the function to replicate the rpois... command you used earlier 100
    times and store the result in a new variable called my_pois.
  CorrectAnswer: my_pois <- replicate(100, rpois(5, 10))
  AnswerTests: match_call('my_pois <- replicate(100, rpois(5, 10))')
  Hint: my_pois <- replicate(100, rpois(5, 10)) will repeat the operation 100 times and store
    the result.

- Class: cmd_question
  Output: Take a look at the contents of my_pois.
  CorrectAnswer: my_pois
  AnswerTests: omnitest('my_pois')
  Hint: Print the contents of my_pois to the console.

- Class: cmd_question
  Output: replicate() created a matrix, each column of which contains 5 random numbers
    generated from a Poisson distribution with mean 10. Now we can find the mean of each
    column in my_pois using the colMeans() function. Store the result in a variable called cm.
  CorrectAnswer: cm <- colMeans(my_pois)
  AnswerTests: omnitest('cm <- colMeans(my_pois)')
  Hint: Use cm <- colMeans(my_pois) to create a vector of column means, storing the result in
    cm.

- Class: cmd_question
  Output: And let's take a look at the distribution of our column means by plotting a
    histogram.
  CorrectAnswer: hist(cm)
  AnswerTests: omnitest('hist(cm)')
  Hint: hist(cm) will give you a histogram of column means.

- Class: text
  Output: Looks like our column means are almost normally distributed, right? That's the
    Central Limit Theorem at work, but that's a lesson for another day!

- Class: text
  Output: All of the standard probability distributions are built into R, including
    Student's t (rt()), exponential (rexp()), chi-squared (rchisq()), gamma
    (rgamma()) ... Well, you see the pattern.

- Class: text
  Output: The Student's t distribution is very important in psychology. Every time you run
    a Student's t-test, you get a t-value. It is thanks to the known characteristics of the
    t-distribution that we can determine the p-value associated with any given value of t.
    
- Class: text
  Output: "The story behind why the distribution and the test are named after \"Student\" is
    rather interesting. The guy who invented them worked in industry and the company had had
    some bad experience with employees disclosing trade secrets and issued a blanket ban on
    any work-related publication."

- Class: text
  Output: "Our stats wiz had to convince the company that a maths paper
    was of no danger to their business in order to let him publish his findings. They allowed
    him to do so but he was required to use a pseudonym so that other employees don't
    complain."
        
- Class: text
  Output: "And so he chose the pen name \"Student\". The company in question was Guiness and
    Student's real name was... you guessed it, William Sealy Gosset. Cool story, I know!"
    
- Class: text
  Output: "Anyway, now that we've covered the r*** functions, let me tell you a bit about the
    other variants."
    
- Class: text
  Output: "The p*** functions give you the probability (p-value) associated with a given
    (or lower) value following one of the distributions I mentioned above. In other words,
    it gives you the area under the distribution curve to the left of the value you input into
    the function."
    
- Class: cmd_question
  Output: For instance, if you want to know the probability of throwing a fair coin 100 times
    and getting 50 or fewer heads, you would use pbinom(50, 100, prob = 0.5). Try it now.
  CorrectAnswer: pbinom(50, 100, prob = 0.5)
  AnswerTests: match_call('pbinom(50, 100, prob = 0.5)')
  Hint:
  
- Class: cmd_question
  Output: As you can see it is slightly more than 50%. Now, if you want to know the p-value
    associated with the other end of the distribution (51 or more heads), you can include the
    lower.tail = FALSE argument in the command. Go ahead!
  CorrectAnswer: pbinom(50, 100, prob = 0.5, lower.tail = FALSE)
  AnswerTests: any_of_exprs('pbinom(50, 100, prob = 0.5, lower.tail = FALSE)', 'pbinom(50, 100, prob = 0.5, lower.tail = F)')
  Hint:
  
- Class: text
  Output: "The q*** functions is the reverse of the p*** function: you give it the p-value
    (AKA the quantile) and it returns the associated value. It is used in pretty much the
    same way as p***."

- Class: cmd_question
  Output: To see what I mean, let's say you want to know what number of heads (or fewer)
    give you the p-value of .5397946, if you flip a fair coin 100 times. I know you already
    know the answer but I want to illustrate the relationship between p*** and q*** functions.
    Use the qbinom() function to find out.
  CorrectAnswer: qbinom(0.5397946, 100, prob = 0.5)
  AnswerTests: match_call('qbinom(0.5397946, 100, prob = 0.5)')
  Hint: Just type qbinom(0.5397946, 100, prob = 0.5).

- Class: text
  Output: "I hope that makes sense. Now, finally, the d*** (density) functions. These
    functions give you the probability density function of a given distribution for a given
    value. In other words, they give you the probability of that value alone, not the
    entire right or left hand side of the distribution like p*** does."
    
- Class: cmd_question
  Output: So what's the probability of getting *exactly* 50 heads if you flip a fair coin 100
    times? Let's find out using dbinom()!
  CorrectAnswer: dbinom(50, 100, prob = 0.5)
  AnswerTests: match_call('dbinom(50, 100, prob = 0.5)')
  Hint: That would be dbinom(50, 100, prob = 0.5).
  
- Class: text
  Output: "So the probability is just under 8%. To prove to you that it is indeed the p
    associated with throwing a fair coin 100 times and getting 50 heads, consider this.
    pbinom(50, 100, 0.5) gives you the p-value for 50 or fewer heads in this experiment.
    So to get the p of exactly 50, you can simply subtract the p-value of 49 or fewer heads,
    right?"
    
- Class: cmd_question
  Output: Try it now. Subtract the function that gives you the p-value of 49 or fewer heads
    from the one that gives you the p-value of 50 or fewer heads.
  CorrectAnswer: pbinom(50, 100, 0.5) - pbinom(49, 100, 0.5)
  AnswerTests: match_call('pbinom(50, 100, 0.5) - pbinom(49, 100, 0.5)')
  Hint: That's pbinom(50, 100, 0.5) - pbinom(49, 100, 0.5), isn't it?
  
- Class: text
  Output: We get the same value. Cool, innit?
  
- Class: text
  Output: Since you now know what the d*** functions do, let's briefly return to the
    histogram you made earlier.
    
- Class: cmd_question
  Output: "Save hist(cm) into an object called \"h\"."
  CorrectAnswer: h <- hist(cm)
  AnswerTests: omnitest('h <- hist(cm)')
  Hint: Just type h <- hist(cm).
  
- Class: text
  Output: I mentioned that the distribution looked kind of normal but it would be nice to
    have a normal curve drawn over the bars, wouldn't it? Let me show you how it's done.
    
- Class: cmd_question
  Output: What you want to do is to draw a line over the plot. For that, we have the lines()
    function. Pull up its documentation now.
  CorrectAnswer: ?lines
  AnswerTests: omnitest(correctExpr='?lines')
  Hint: Use '?lines' to pull up the documentation for the lines() function.
  
- Class: text
  Output: As you can see, we need to give R vectors of x and y coordinates so that it knows
    how to draw the line. Let's start with the more straightforward x coordinates.
    
- Class: text
  Output: "Since the plot only depicts values stored in \"cm\", it is a good idea to draw
    the line all the way from the smallest value of cm to the largest. 40 equally spaced
    points between these two values should be enough for R to draw a reasonably smooth normal
    curve."
    
- Class: cmd_question
  Output: Use the seq() function to generate 40 numbers from min(cm to max(cm) and store them
    in an object called xfit.
  CorrectAnswer: xfit <- seq(min(cm), max(cm), length = 40)
  AnswerTests: match_call('xfit <- seq(min(cm), max(cm), length = 40)')
  Hint: That's xfit <- seq(min(cm), max(cm), length = 40).
  
- Class: cmd_question
  Output: Look at xfit now to see what happened.
  CorrectAnswer: xfit
  AnswerTests: omnitest(correctVal= 'xfit')
  Hint:
  
- Class: text
  Output: Now, for every element in xfit, which represents the x coordinate for the points on
    the plot to be connected by the line, we need a corresponding y coordinate.
  
- Class: text
  Output: If the y axis of the histogram stored in h were a density plot (hist(cm, freq =
    FALSE)), you could just use dnorm() to find the y coordintes for each of the xfit elements.
    You would do it by providing xfit as the fist argument of dnorm(), mean of cm as tghe mean
    and the standard deviation of cm as the sd of the normal distribution.
    
- Class: cmd_question
  Output: Try to do it now and store the result into an object called \"yfit\".
  CorrectAnswer: yfit<-dnorm(xfit,mean=mean(cm),sd=sd(cm))
  AnswerTests: match_call('yfit<-dnorm(xfit,mean=mean(cm),sd=sd(cm))')
  Hint: You nead to use dnorm(), mean() and sd().

- Class: cmd_question
  Output: Look at yfit now to see what happened.
  CorrectAnswer: yfit
  AnswerTests: omnitest(correctVal= 'yfit')
  Hint:
  
- Class: text
  Output: However the h plot is not a density plot but a frequency plot. That means that its
    area does not add up to 1. Therefore, you need to scale up the yfit variable to match
    the scale of the y axis.
    
- Class: cmd_question
  Output: "If you do not scale the yfit variable and give it to the lines() function, R will
    draw a curve that, while normal, is really flat. See for yourself; type lines(xfit, yfit,
    col=\"blue\", lwd=2)."
  CorrectAnswer: lines(xfit, yfit, col="blue", lwd=2)
  AnswerTests: match_call('lines(xfit, yfit, col="blue", lwd=2)')
  Hint: "Type lines(xfit, yfit, col=\"blue\", lwd=2)."
  
- Class: text
  Output: See what I mean? Let's scale the ylim variable then.
  
- Class: cmd_question
  Output: "What you want to do is basically multiply the yfit vector by the length of cm and
     by the width of the individual bars of the histogram h like this:
     yfit*diff(h$mids[1:2])*length(cm). Reassign these values to the yfit vector now."
  CorrectAnswer: yfit <- yfit*diff(h$mids[1:2])*length(cm) 
  AnswerTests: any_of_exprs('yfit <- yfit*diff(h$mids[1:2])*length(cm)', 'yfit <- yfit*diff(hist(cm)$mids[1:2])*length(cm)')
  Hint: "Type yfit <- yfit*diff(h$mids[1:2])*length(cm)."
  
- Class: text
  Output: That's kind of okay but I don't like two things about the plot. Firstly, we only
    want the proper normal curve there, not the flat one. Secondly, I would like to see the
    entire line and not have the top of it cut off. All of this can be done in two steps.

- Class: cmd_question
  Output: "First, create a new histogram of cm and store it in h just like you did earlier
    but this time around, use the ylim argument to set the limits of the y axis to 0 and 25,
    instead of the c(0, 20) R chose by default."
  CorrectAnswer: h <- hist(cm, ylim = c(0, 25)
  AnswerTests: match_call('h <- hist(cm, ylim = c(0, 25)')
  Hint: "Type h <- hist(cm, ylim = c(0, 25)."
  
- Class: cmd_question
  Output: "See how the y axis changed? Now, all you need to do is simply to reuse the lines()
    command from earlier on."
  CorrectAnswer: lines(xfit, yfit, col="blue", lwd=2)
  AnswerTests: match_call('lines(xfit, yfit, col="blue", lwd=2)')
  Hint: "Type lines(xfit, yfit, col=\"blue\", lwd=2)."

- Class: text
  Output: Et voila, your histogram with a superposed normal curve! Pretty neat, don't you
    think?
  
- Class: text
  Output: Okay, one last thing. Back to the t-distribution and t-tests. Like I said,
    the value of a t you get if you run a t-test falls somewhere within the t distribution
    and thus has an associated p-value. Now, unlike the standard normal distribution which
    has always the same shape, the shape of the t distribution changes based on degrees of
    freedom. As the number of df gets bigger, the t-distribution approximates the standard
    normal.
    
- Class: text
  Output: Let's say you ran an experiment where you measured reaction time and you want to
    compare the mean of your participants' RT to some hypothetical mean expected under
    the null hypothesis. You tested 30 participants, which gives you 29 degrees of freedom,
    and their mean RT was larger than the one expected under the null hypothesis.
    You ran your one-sample t-test and got the value of 1.8. Now you know this is a t-value
    and as such, falls within the Student's t distribution with 29 degrees of freedom.
    
- Class: mult_question
  Output: Which function would you use to find the p-value of t of 1.8 or more?
  AnswerChoices: pt(); dt(); rt(); qt()
  CorrectAnswer: pt()
  AnswerTests: omnitest(correctVal= 'pt()')
  Hint: "You are looking for the p-value. The *p* value..."  

- Class: cmd_question
  Output: First, pull up the documentation for pt() to see how it's used.?
  CorrectAnswer: ?pt
  AnswerTests: omnitest('?pt')
  Hint: Type ?pt to view its help file.
  
- Class: cmd_question
  Output: Now, find the p-value associated with t(df=29) = 1.8 or more. Don't worry about
    the non-centrality parameter (ncp) argument.
  CorrectAnswer: pt(1.8, 29, lower.tail = FALSE)
  AnswerTests: any_of_exprs('pt(1.8, 29, lower.tail = FALSE)', 'pt(1.8, 29, lower.tail = F)')
  Hint: Don't forget the lower.tail argument.
  
- Class: text
  Output: Great, your p-value is .041, which is < .05. Congrats, not only do you now
    understand how we get p-values from t-values but, on top of that, you have a significant
    result. Hurrah!
    
- Class: text
  Output: I think this is a good point at which to end. I'm getting a wee bit tired anyway.
    Well done on completing Lesson 6! Catch you later. :)
